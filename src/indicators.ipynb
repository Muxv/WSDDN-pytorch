{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import VOCDectectionDataset\n",
    "from sklearn.metrics import average_precision_score\n",
    "from model import *\n",
    "from utils import *\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propose_way = \"edge_box\"\n",
    "pretrained = \"vgg16\"\n",
    "traindata = VOCDectectionDataset(\"~/data/\", 2007, 'trainval', region_propose=propose_way, do_transform=True)\n",
    "traindata_loader = data.DataLoader(traindata, 1, shuffle=False)\n",
    "wsddn = WSDDN_VGG16().to(DEVICE)\n",
    "wsddn.load_state_dict(torch.load(SAVE_PATH + get_model_name(propose_way, \"2007\" , f\"wsddn_{pretrained}\") + \".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94251f881a64fdc994343f5758a98d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='CorLoc', max=5011.0, style=ProgressStyle(description_widtâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorLoc is [0.5        0.76923077 0.53333333 0.30434783 0.23809524 1.\n",
      " 0.75609756 0.34482759 0.29411765 0.66666667 0.36       0.625\n",
      " 0.66666667 0.86363636 0.2393617  0.42105263 0.72727273 0.36363636\n",
      " 0.60714286 0.30434783]\n",
      "CorLoc is [0.48       0.56603774 0.52941176 0.23684211 0.27659574 0.78571429\n",
      " 0.74482759 0.35384615 0.37894737 0.67741935 0.32608696 0.6\n",
      " 0.61111111 0.74       0.245      0.36842105 0.61904762 0.34042553\n",
      " 0.56818182 0.37037037]\n",
      "CorLoc is [0.47761194 0.63157895 0.50485437 0.28571429 0.29166667 0.74468085\n",
      " 0.72727273 0.41836735 0.37593985 0.74       0.33846154 0.5625\n",
      " 0.56097561 0.76       0.22128378 0.38095238 0.62857143 0.42424242\n",
      " 0.55555556 0.45205479]\n",
      "CorLoc is [0.53488372 0.62       0.46575342 0.30136986 0.31632653 0.71212121\n",
      " 0.69117647 0.47692308 0.34659091 0.75438596 0.34146341 0.53448276\n",
      " 0.54867257 0.78350515 0.22487437 0.31958763 0.63636364 0.39583333\n",
      " 0.57843137 0.48514851]\n",
      "CorLoc is [0.56637168 0.61788618 0.46629213 0.28888889 0.29365079 0.70238095\n",
      " 0.67930029 0.49101796 0.34080717 0.71428571 0.36363636 0.53424658\n",
      " 0.59310345 0.77952756 0.22609562 0.31451613 0.63461538 0.39823009\n",
      " 0.59055118 0.51181102]\n",
      "CorLoc is [0.53787879 0.59868421 0.46341463 0.25862069 0.28767123 0.70408163\n",
      " 0.6691358  0.48019802 0.33828996 0.73493976 0.3442623  0.53816794\n",
      " 0.58823529 0.75163399 0.22831424 0.32432432 0.61290323 0.39259259\n",
      " 0.62179487 0.53061224]\n",
      "CorLoc is [0.54716981 0.60344828 0.46581197 0.26515152 0.30857143 0.7027027\n",
      " 0.66457023 0.47234043 0.33333333 0.73737374 0.33566434 0.51485149\n",
      " 0.59701493 0.78409091 0.23141655 0.32941176 0.61428571 0.38853503\n",
      " 0.6284153  0.52      ]\n",
      "CorLoc is [0.54098361 0.585      0.46441948 0.28666667 0.30049261 0.68382353\n",
      " 0.66173752 0.46494465 0.33798883 0.71559633 0.32727273 0.52352941\n",
      " 0.61403509 0.78061224 0.23623995 0.34020619 0.5974026  0.40331492\n",
      " 0.6097561  0.54411765]\n",
      "CorLoc is [0.55450237 0.56880734 0.4557377  0.28823529 0.29680365 0.68518519\n",
      " 0.65977742 0.46       0.33333333 0.696      0.33152174 0.52864583\n",
      " 0.61776062 0.75813953 0.23917869 0.32727273 0.61363636 0.38164251\n",
      " 0.61373391 0.52631579]\n",
      "CorLoc is [0.54621849 0.5661157  0.45151515 0.29608939 0.31147541 0.6827957\n",
      " 0.65730337 0.45400593 0.34009009 0.70212766 0.325      0.52142857\n",
      " 0.61188811 0.76639344 0.23576424 0.32244898 0.62105263 0.39912281\n",
      " 0.62548263 0.53515625]\n",
      "\n",
      "CorLoc is [0.54621849 0.56378601 0.45151515 0.29281768 0.31147541 0.6827957\n",
      " 0.65638149 0.45400593 0.33932584 0.70212766 0.325      0.52256532\n",
      " 0.6097561  0.76326531 0.23605578 0.32244898 0.61458333 0.39737991\n",
      " 0.62835249 0.53515625]\n",
      "mean CorLoc is 0.4977506413187952\n"
     ]
    }
   ],
   "source": [
    "positives = np.array([0 for _ in range(20)]) # \n",
    "hits = np.array([0 for _ in range(20)]) # \n",
    "n = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    wsddn.eval();\n",
    "    for img, gt_box, gt_target, regions, scores in tqdm(traindata_loader, \"CorLoc\"):\n",
    "        n += 1\n",
    "        regions = regions.to(DEVICE)\n",
    "        if propose_way != \"edge_box\":\n",
    "            scores = None\n",
    "        else:\n",
    "            scores = scores.to(DEVICE)\n",
    "        img = img.to(DEVICE)\n",
    "        regions = regions.to(DEVICE)\n",
    "        gt_box = gt_box.to(DEVICE)\n",
    "        combined_scores, fc7= wsddn(img, regions, scores)\n",
    "        \n",
    "        for c in range(20):\n",
    "            if gt_target[0][c] == 0.0:\n",
    "                continue\n",
    "            else:\n",
    "                positives[c] += 1\n",
    "                gt_regions = gt_box[0]\n",
    "                cls_scores = combined_scores[:, c]\n",
    "                most_confident_one = torch.argmax(cls_scores)\n",
    "                most_confident_region = regions[0][most_confident_one:most_confident_one+1]\n",
    "                IOU = one2allbox_iou(most_confident_region, gt_regions)\n",
    "                if (IOU >= 0.5).sum() >= 1.0:\n",
    "                    hits[c] += 1\n",
    "        if n % 500 == 0:\n",
    "            print(f\"CorLoc is {hits/positives}\")\n",
    "    corloc = hits/positives\n",
    "    print(f\"CorLoc is {corloc}\")\n",
    "    print(f\"mean CorLoc is {(corloc).sum()/20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CorLoc is [0.6302521  0.57613169 0.40909091 0.32596685 0.25819672 0.66129032\n",
    " 0.71388499 0.47477745 0.3011236  0.55319149 0.13       0.38004751\n",
    " 0.6445993  0.74285714 0.2435259  0.33877551 0.57291667 0.28820961\n",
    " 0.66283525 0.5703125 ]\n",
    "mean CorLoc is 0.4738992749533109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5, device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(cls_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.8015e-03, 1.0073e-06, 4.8591e-05, 6.4935e-04, 6.0962e-02, 7.7546e-01,\n",
       "        1.8202e-07, 6.9581e-03, 5.6128e-05, 1.4432e-06, 7.3070e-05, 4.7705e-04,\n",
       "        5.4533e-05, 1.5168e-09, 5.5606e-03, 2.2619e-04, 3.8841e-04, 1.5340e-06,\n",
       "        9.6877e-10, 9.0330e-04, 1.5512e-03, 8.5839e-04, 3.2774e-06, 7.0984e-06,\n",
       "        1.8416e-06, 1.1724e-09, 4.8746e-05, 1.7280e-02, 6.4380e-06, 1.2533e-02,\n",
       "        1.1148e-07, 7.8140e-10, 1.2976e-04, 2.9895e-04, 8.0396e-03, 1.5438e-02,\n",
       "        9.2735e-04, 1.6008e-05, 4.3926e-05, 1.5715e-02, 7.8783e-08, 2.2923e-06,\n",
       "        3.6833e-09, 1.6496e-07, 1.2807e-09, 2.2752e-08, 6.5740e-07, 1.1553e-03,\n",
       "        1.6359e-10, 6.9929e-03, 4.5150e-06, 1.2659e-09, 2.5307e-06, 8.9998e-03,\n",
       "        2.0705e-08, 5.4474e-08, 2.1282e-05, 1.4078e-04, 2.3477e-04, 1.0672e-07,\n",
       "        2.5046e-05, 1.1427e-04, 4.5559e-03, 2.3163e-04, 8.4948e-08, 2.9120e-06,\n",
       "        6.4301e-05, 1.3498e-04, 1.2009e-07, 1.6424e-07, 2.8923e-05, 2.8104e-05,\n",
       "        4.8467e-10, 6.0721e-06, 1.6605e-04, 3.3379e-03, 4.5680e-09, 1.0862e-04,\n",
       "        3.9309e-08, 1.3027e-04, 1.3220e-06, 1.2929e-08, 1.9179e-04, 5.1686e-04,\n",
       "        1.1491e-07, 1.1932e-09, 2.7513e-04, 1.8435e-03, 3.8550e-08, 3.0489e-09,\n",
       "        4.1701e-08, 8.7745e-07, 1.4298e-04, 3.4857e-09, 3.8267e-06, 3.1387e-03,\n",
       "        1.4634e-07, 2.1666e-08, 2.4423e-06, 6.6740e-08, 3.9086e-08, 1.2156e-07,\n",
       "        1.5067e-06, 2.0120e-04, 3.5812e-08, 2.0785e-08, 6.6214e-07, 1.1687e-03,\n",
       "        1.4149e-04, 3.8011e-07, 7.7411e-05, 3.2910e-06, 1.3307e-08, 1.4389e-08,\n",
       "        3.0493e-08, 9.9615e-09, 3.8602e-05, 7.0126e-09, 7.4691e-08, 5.9436e-05,\n",
       "        3.4312e-04, 7.3162e-09, 4.2284e-04, 1.5453e-07, 7.3230e-08, 4.2115e-08,\n",
       "        2.6502e-04, 1.0110e-06, 2.3029e-06, 1.8150e-07, 2.2471e-09, 6.9555e-05,\n",
       "        8.6345e-10, 2.5778e-04, 1.7475e-07, 1.3767e-06, 2.6513e-09, 9.9667e-06,\n",
       "        9.8403e-07, 9.1450e-05, 5.9567e-10, 7.5924e-04, 1.6332e-10, 3.7333e-09,\n",
       "        1.0430e-08, 4.7271e-08, 9.8087e-08, 1.4538e-08, 5.3159e-06, 2.4634e-08,\n",
       "        1.2422e-07, 2.4602e-07, 7.3538e-10, 6.3640e-10, 2.7108e-06, 3.9753e-10,\n",
       "        3.1477e-06, 3.4619e-08, 1.3315e-04, 2.0276e-07, 1.5644e-06, 3.8370e-08,\n",
       "        4.5045e-08, 4.5822e-07, 9.5363e-07, 3.3769e-04, 6.5452e-07, 1.2291e-09,\n",
       "        4.4156e-04, 5.6180e-09, 3.1870e-08, 1.0923e-05, 2.1540e-08, 1.3050e-07,\n",
       "        2.2180e-07, 3.0932e-07, 9.3270e-08, 1.1347e-07, 4.2085e-07, 9.5098e-09,\n",
       "        7.3469e-08, 6.7700e-05, 3.8387e-09, 1.9194e-08, 1.3610e-08, 5.6724e-10,\n",
       "        4.2394e-06, 2.3678e-06, 3.6482e-07, 1.8941e-05, 1.3812e-09, 1.6170e-07,\n",
       "        9.2815e-10, 1.5948e-05, 3.1809e-09, 1.4456e-07, 2.4459e-05, 1.6727e-05,\n",
       "        2.5935e-08, 5.0207e-08, 1.0596e-09, 1.5275e-05, 3.9796e-04, 2.2206e-05,\n",
       "        1.5307e-09, 2.6857e-05, 5.8081e-04, 1.6020e-08, 3.8740e-07, 8.4565e-08,\n",
       "        2.4981e-09, 4.3845e-05, 8.3229e-06, 4.0639e-06, 4.8810e-05, 1.2137e-07,\n",
       "        1.6325e-09, 1.9136e-07, 6.7693e-06, 2.4467e-05, 4.6699e-05, 1.9778e-07,\n",
       "        1.1167e-09, 1.4149e-08, 6.7640e-08, 3.6732e-07, 1.6005e-03, 3.4456e-06,\n",
       "        8.3712e-10, 1.1035e-03, 5.5942e-07, 9.5880e-06, 9.7084e-07, 7.7248e-06,\n",
       "        2.9916e-08, 2.2552e-05, 1.7960e-03, 6.2294e-10, 7.4832e-04, 1.0967e-09,\n",
       "        5.8676e-07, 4.0087e-10, 1.2126e-06, 1.6924e-08, 1.5973e-08, 2.4885e-10,\n",
       "        7.9274e-05, 2.8322e-06, 1.1424e-05, 3.6163e-08, 9.4261e-10, 9.1560e-10,\n",
       "        6.8215e-06, 1.9187e-08, 7.7663e-05, 7.0128e-07, 1.7491e-09, 2.1839e-09,\n",
       "        1.2495e-08, 4.2343e-08, 4.3183e-08, 6.1303e-06, 1.9519e-07, 1.7913e-07,\n",
       "        1.6364e-05, 2.3562e-06, 5.1776e-08, 6.9232e-07, 5.6620e-10, 7.6120e-09,\n",
       "        5.9208e-09, 1.1491e-06, 2.9543e-09, 2.5130e-08, 6.6415e-08, 7.0104e-08,\n",
       "        4.2284e-10, 7.3974e-05, 1.3453e-07, 6.1681e-06, 8.6028e-08, 2.6035e-08,\n",
       "        1.7832e-07, 2.8568e-04, 8.3494e-06, 3.3246e-07, 7.3003e-08, 4.0229e-03,\n",
       "        1.0108e-08, 9.4645e-10, 1.0026e-06, 3.6012e-09, 8.6332e-07, 1.2490e-08,\n",
       "        6.2047e-07, 2.7550e-07, 2.1343e-09, 2.3391e-07, 2.5044e-04, 7.7200e-05,\n",
       "        9.9033e-05, 1.0643e-09, 2.3915e-10, 1.2002e-05, 9.5163e-09, 1.0965e-04,\n",
       "        1.1134e-07, 2.0500e-10, 1.9986e-07, 1.6233e-09, 2.5757e-08, 8.0747e-08,\n",
       "        1.4546e-03, 2.3235e-04, 2.0625e-08, 1.9560e-06, 6.9544e-03, 5.5521e-09,\n",
       "        1.2281e-05, 6.5374e-08, 1.2383e-06, 6.0178e-05, 7.6763e-07, 5.4656e-06,\n",
       "        4.0075e-09, 3.2332e-07, 8.6046e-10, 1.2228e-06, 1.5586e-07, 2.4506e-09,\n",
       "        6.1799e-08, 1.0404e-08, 2.1968e-09, 1.8508e-06, 2.2692e-05, 7.0648e-07,\n",
       "        5.2054e-07, 1.0267e-05, 2.6975e-04, 7.2328e-10, 3.8571e-06, 2.0529e-09,\n",
       "        1.4574e-06, 2.4223e-04, 7.4583e-08, 6.4281e-10, 1.2548e-05, 2.3053e-05,\n",
       "        1.1287e-08, 1.0554e-05, 5.2411e-08, 7.8662e-06, 8.5421e-06, 6.4926e-09,\n",
       "        4.2630e-07, 9.0358e-07, 4.0184e-09, 4.4502e-09, 1.4411e-04, 1.3923e-06,\n",
       "        4.0565e-08, 1.0229e-05, 8.6491e-06, 3.7647e-08, 1.2333e-05, 6.8229e-10,\n",
       "        5.6952e-07, 1.5345e-05, 7.1286e-09, 8.6148e-09, 6.7533e-08, 6.0624e-10,\n",
       "        9.1560e-09, 6.2216e-10, 6.6843e-06, 1.6272e-07, 1.5913e-06, 1.1965e-07,\n",
       "        4.8063e-10, 1.2718e-09, 4.8310e-09, 1.7305e-10, 2.8848e-07, 2.0824e-09,\n",
       "        1.7005e-09, 1.1659e-09, 1.9103e-04, 1.8055e-09, 4.7837e-09, 4.1292e-06,\n",
       "        1.7043e-07, 1.1918e-07, 1.2121e-06, 2.5448e-06, 3.3259e-08, 3.7039e-07,\n",
       "        1.9411e-10, 3.2475e-07, 8.7053e-08, 2.9890e-07, 2.0509e-09, 1.1450e-04,\n",
       "        1.8711e-07, 6.4424e-10, 1.2317e-07, 4.1145e-10, 4.4899e-04, 3.9929e-08,\n",
       "        9.2176e-09, 2.7997e-08, 2.8501e-05, 2.7775e-10, 2.6331e-10, 1.3251e-04,\n",
       "        4.0455e-09, 6.9007e-10, 9.1116e-08, 3.9504e-06, 1.1898e-07, 7.5101e-07,\n",
       "        5.0154e-09, 1.2948e-06, 1.2619e-09, 8.9701e-09, 1.5799e-05, 1.9949e-10,\n",
       "        9.0106e-10, 4.0309e-10, 3.0899e-09, 7.9220e-10, 5.4830e-07, 5.9709e-09,\n",
       "        7.3739e-07, 4.1555e-06, 1.2986e-07, 1.5779e-09, 6.9327e-09, 7.2780e-10,\n",
       "        4.7832e-09, 1.0348e-08, 1.5493e-03, 4.3676e-06, 4.5525e-08, 3.7153e-10,\n",
       "        3.9903e-07, 3.9262e-10, 3.7167e-10, 1.1072e-09, 1.9296e-10, 4.0980e-09,\n",
       "        2.8906e-09, 9.4283e-10, 5.9137e-05, 2.5612e-10, 2.3151e-06, 2.4710e-09,\n",
       "        1.7888e-08, 3.7009e-10, 1.5204e-08, 2.5659e-07, 1.0964e-09, 7.1073e-10,\n",
       "        6.5147e-10, 1.9056e-09, 1.8689e-08, 4.2109e-05, 3.8764e-10, 1.1686e-09,\n",
       "        5.0751e-10, 2.9219e-07, 7.8019e-10, 1.5812e-07, 1.0439e-07, 2.1682e-08,\n",
       "        1.1746e-05, 1.2035e-07, 1.0745e-08, 4.8522e-10, 2.2106e-10, 3.2896e-09,\n",
       "        1.1187e-07, 2.1222e-09, 2.3442e-07, 4.0261e-10, 3.1753e-09, 3.9957e-10,\n",
       "        1.4685e-07, 1.0521e-09, 4.3483e-07, 2.2295e-09, 2.8154e-03, 9.3242e-08,\n",
       "        4.4084e-10, 7.8462e-09, 1.7856e-07, 1.9857e-07, 1.1723e-08, 7.6377e-10,\n",
       "        1.0214e-06, 1.6931e-07, 3.7414e-10, 8.4864e-09, 4.4127e-09, 3.3342e-10,\n",
       "        4.9288e-05, 3.1780e-07, 1.3741e-09, 5.9795e-09, 5.9519e-08, 1.1174e-09,\n",
       "        5.3309e-07, 1.5499e-07, 2.2106e-10, 2.5168e-08, 2.0635e-04, 4.5143e-05,\n",
       "        3.6760e-10, 1.0633e-09, 5.6993e-10, 1.1468e-09, 6.9128e-07, 1.2296e-06,\n",
       "        6.7502e-08, 3.7706e-10, 3.5122e-10, 2.6474e-05, 1.2173e-10, 2.3921e-06,\n",
       "        1.0339e-07, 1.4466e-08, 5.1076e-10, 8.0450e-11, 4.3155e-10, 4.6360e-10,\n",
       "        9.3853e-09, 2.3253e-08, 4.4535e-08, 3.2936e-10, 2.3428e-09, 3.4797e-10,\n",
       "        2.6289e-09, 5.8338e-06, 5.8261e-10, 9.9208e-06, 5.3929e-10, 1.3856e-08,\n",
       "        4.5262e-09, 4.2525e-07, 4.3807e-10, 1.9887e-07, 3.8333e-10, 2.0581e-10,\n",
       "        7.7802e-10, 2.2106e-10, 1.0973e-05, 3.7378e-08, 7.9551e-10, 2.3832e-08,\n",
       "        1.4840e-06, 1.0917e-09, 4.4815e-09, 2.0767e-08, 2.1275e-09, 1.9182e-10,\n",
       "        4.1959e-10, 3.5942e-07, 9.3198e-08, 3.1790e-10, 7.0956e-10, 1.1009e-09,\n",
       "        9.7828e-10, 2.7457e-10, 7.6841e-10, 3.4826e-10, 3.6229e-10, 4.0646e-10,\n",
       "        4.9547e-10, 7.9332e-10, 1.3280e-09, 9.3301e-07, 8.0942e-09, 5.4110e-10,\n",
       "        4.1247e-10, 1.3543e-09, 5.2394e-09, 6.2017e-10, 1.6042e-08, 5.4313e-10,\n",
       "        2.2106e-10, 3.9700e-10, 2.9684e-10, 4.5500e-10, 8.2763e-09, 2.8380e-10,\n",
       "        2.5175e-10, 4.7630e-10, 5.3532e-10, 1.8343e-07, 4.8301e-10, 2.2738e-06,\n",
       "        1.8465e-09, 2.9267e-08, 4.4820e-10, 6.6831e-10, 2.6901e-07, 1.6117e-05,\n",
       "        2.3043e-09, 2.8707e-09, 7.2033e-10, 4.3544e-10, 1.0478e-09, 9.0374e-10,\n",
       "        3.4635e-10, 1.1629e-08, 9.9255e-10, 1.2232e-09, 5.7461e-10, 1.3138e-09,\n",
       "        1.9254e-08, 5.0802e-10, 7.3266e-10, 2.2176e-10, 4.8905e-05, 1.3798e-10,\n",
       "        7.2985e-10, 3.3899e-10, 2.7334e-05, 3.5632e-09, 4.7542e-10, 2.2106e-10,\n",
       "        6.9181e-10, 3.4301e-10, 4.4568e-06, 7.3811e-10, 6.7784e-10, 3.4285e-10,\n",
       "        6.6387e-10, 1.1162e-09, 1.8025e-09, 8.2160e-06, 7.2040e-10, 4.9594e-10,\n",
       "        1.2055e-09, 4.1499e-10, 2.4477e-10, 1.1578e-09, 6.6570e-06, 4.5012e-08,\n",
       "        3.3554e-10, 3.0887e-10, 4.4331e-10, 2.5738e-06, 6.3298e-10, 3.0546e-09,\n",
       "        1.2295e-09, 6.4648e-10, 1.5680e-09, 3.8400e-10, 1.2506e-09, 5.4902e-10,\n",
       "        1.2008e-07, 1.4097e-09, 2.9540e-10, 2.6153e-09, 6.3288e-08, 8.5692e-10,\n",
       "        7.9561e-08, 3.4018e-10, 1.3629e-07, 3.2098e-10, 1.7889e-08, 3.2540e-10,\n",
       "        4.9588e-10, 1.3420e-09, 7.2749e-10, 6.2336e-08, 2.5063e-07, 8.2751e-10,\n",
       "        7.9973e-10, 4.9579e-10, 7.3759e-10, 9.2048e-10, 8.5466e-08, 5.7569e-10,\n",
       "        2.6998e-10, 1.2041e-07, 2.2723e-05, 1.2402e-06, 6.4043e-10, 2.3906e-10,\n",
       "        1.1033e-09, 3.0811e-07, 8.2887e-10, 6.5862e-10, 1.7531e-10, 8.5763e-10,\n",
       "        3.1261e-10, 3.3232e-10, 4.5235e-10, 3.9506e-10, 1.4260e-09, 5.6230e-10,\n",
       "        4.9866e-10, 3.5909e-10, 4.7642e-08, 4.1527e-10, 2.1766e-05, 6.3227e-10,\n",
       "        4.3661e-08, 7.6128e-10, 3.2737e-10, 5.9180e-10, 6.4092e-10, 1.0427e-09,\n",
       "        3.0737e-10, 8.3079e-05, 2.5675e-10, 2.1587e-05, 6.6576e-09, 5.2661e-10,\n",
       "        1.3174e-09, 1.0424e-09, 4.4180e-09, 5.0409e-10, 1.5586e-09, 4.3147e-10,\n",
       "        1.0180e-08, 1.6937e-10, 6.0795e-10, 5.1975e-09, 3.1930e-10, 2.9058e-10,\n",
       "        5.9683e-10, 3.8943e-10, 3.2259e-10, 6.0231e-10, 7.7729e-10, 6.5515e-10,\n",
       "        1.8011e-09, 4.9635e-10, 6.1814e-10, 5.6448e-10, 2.9522e-10, 3.2395e-05,\n",
       "        2.6582e-10, 2.9858e-10, 3.4250e-10, 7.7521e-06, 3.9293e-10, 8.3328e-09,\n",
       "        9.6700e-10, 1.0102e-09, 3.9952e-10, 3.0175e-10, 9.9701e-08, 9.3399e-10,\n",
       "        5.9994e-10, 5.3646e-10, 7.9821e-10, 2.2106e-10, 4.9179e-10, 2.4172e-10,\n",
       "        5.5711e-10, 1.9157e-10, 4.2344e-10, 7.6231e-10, 3.6592e-07, 8.2138e-10,\n",
       "        3.0443e-09, 1.4331e-09, 4.5351e-10, 9.1108e-09, 1.2372e-09, 1.6402e-09,\n",
       "        6.7205e-10, 2.1486e-10, 3.8083e-10, 1.8107e-08, 1.4268e-09, 4.6714e-10,\n",
       "        4.0064e-10, 1.9490e-10, 4.4819e-10, 2.6657e-09, 6.0249e-10, 6.1527e-08,\n",
       "        1.5788e-09, 3.2983e-10, 2.7583e-10, 3.7824e-10, 1.1173e-09, 1.4919e-09,\n",
       "        7.3119e-10, 7.3730e-10, 5.6031e-10, 3.8303e-10, 3.9887e-10, 2.8633e-10,\n",
       "        2.8474e-10, 5.3864e-10, 5.1798e-10, 3.0861e-10, 3.9164e-10, 1.4800e-09,\n",
       "        2.2955e-10, 2.1142e-10, 5.2109e-10, 5.3707e-10, 3.0232e-08, 8.3226e-10,\n",
       "        4.2573e-10, 1.4372e-09, 3.3976e-07, 4.8457e-10, 2.5472e-10, 1.2725e-09,\n",
       "        2.3059e-07, 3.0688e-10, 2.8140e-07, 2.8748e-09, 3.6826e-10, 5.0598e-10,\n",
       "        1.6751e-08, 3.6468e-10, 2.1500e-09, 6.9690e-10, 2.4521e-10, 1.7354e-10,\n",
       "        8.4333e-10, 4.0808e-10, 1.9015e-10, 1.6366e-09, 2.9059e-10, 4.9811e-10,\n",
       "        5.6984e-10, 2.3491e-07, 8.6445e-08, 3.7655e-10, 8.0910e-10, 7.9962e-10,\n",
       "        3.0589e-10, 3.6197e-10, 3.5939e-10, 7.0171e-10, 4.1506e-10, 4.2552e-10,\n",
       "        3.3045e-10, 1.9883e-09, 3.6997e-10, 5.5813e-10, 3.5690e-10, 2.1110e-09,\n",
       "        4.3384e-10, 5.5941e-10, 7.9497e-10, 2.2771e-10, 2.0176e-10, 4.5014e-10,\n",
       "        1.9209e-09, 4.7892e-10, 4.4314e-10, 5.8435e-10, 7.2429e-10, 4.6276e-10,\n",
       "        2.6227e-09, 6.7741e-10, 1.4183e-07, 3.2214e-10, 2.4882e-09, 3.3308e-10,\n",
       "        1.0085e-07, 2.7267e-10, 2.5978e-10, 3.6792e-10, 2.1032e-10, 3.3762e-10,\n",
       "        4.0472e-10, 3.1464e-10, 1.4618e-09, 2.4888e-09, 7.4131e-10, 3.7694e-10,\n",
       "        2.9423e-10, 2.3178e-07, 5.3345e-10, 7.4195e-10, 3.0755e-10, 4.3950e-10,\n",
       "        3.6771e-10, 4.4786e-10, 3.1398e-10, 8.1902e-08, 9.8148e-09, 3.4160e-10,\n",
       "        1.3710e-10, 5.8330e-10, 8.4288e-10, 3.5168e-09, 3.0009e-10, 4.0221e-10,\n",
       "        9.0018e-10, 3.3920e-10, 7.1019e-07, 5.4135e-10, 1.6873e-10, 1.8043e-07,\n",
       "        2.8324e-10, 3.1585e-08, 4.1044e-10, 3.6828e-10, 5.7966e-10, 1.5392e-09,\n",
       "        9.6624e-10, 3.9981e-10, 2.1788e-09, 1.1414e-05, 1.4689e-09, 3.6490e-10,\n",
       "        2.6335e-10, 6.4733e-10, 9.7650e-10, 3.4622e-10, 3.1772e-10, 5.0896e-10,\n",
       "        6.7530e-10, 6.0628e-09, 2.3538e-10, 2.1552e-10, 4.7094e-10, 1.0293e-10,\n",
       "        2.4520e-08, 6.1828e-10, 1.5183e-10, 2.2106e-10, 2.2106e-10, 2.0515e-10,\n",
       "        1.0456e-10, 4.9934e-10, 1.7931e-10, 6.0698e-10, 6.8794e-10, 4.6728e-10,\n",
       "        3.4713e-10, 3.1125e-10, 3.1570e-10, 2.9017e-10, 2.6465e-10, 1.1760e-10,\n",
       "        1.0603e-09, 1.8731e-10, 7.0673e-10, 2.1535e-10, 4.8836e-10, 1.0355e-09,\n",
       "        3.8231e-10, 2.3867e-10, 1.0811e-09, 8.8049e-10, 2.6703e-10, 9.2254e-10,\n",
       "        3.8765e-10, 2.9985e-10, 7.9777e-10, 3.6657e-08, 3.9907e-09],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143, 139, 132,  59,  68, 121, 509, 165, 140,  74,  33, 166, 182,\n",
       "       184, 464,  82,  60,  70, 172, 143])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propose_way = \"edge_box\"\n",
    "pretrained = \"alexnet\"\n",
    "traindata = VOCDectectionDataset(\"~/data/\", 2007, 'test', region_propose=propose_way, do_transform=True)\n",
    "traindata_loader = data.DataLoader(traindata, 1, shuffle=False)\n",
    "wsddn = WSDDN_Alexnet().to(DEVICE)\n",
    "wsddn.load_state_dict(torch.load(SAVE_PATH + get_model_name(propose_way, \"2007\" , f\"wsddn_{pretrained}\") + \".pt\"))\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), \"Total\"):\n",
    "    epoch_loss = 0.0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for img, gt_box, gt_target, regions, scores in tqdm(train_loader, f\"Epoch {epoch}\"):\n",
    "        optimizer.zero_grad()\n",
    "        # img   : Tensor(1, 3, h, w)\n",
    "        # gt_tar: Tensor(1, R_gt)\n",
    "        # region: Tensor(1, R, 4)\n",
    "        img = img.to(DEVICE)\n",
    "        regions = regions.to(DEVICE)\n",
    "        gt_target = gt_target.to(DEVICE)\n",
    "        if propose_way != \"edge_box\":\n",
    "            scores = None\n",
    "        else:\n",
    "            scores = scores.to(DEVICE)\n",
    "        combined, fc7 = wsddn(img, regions, scores=scores)\n",
    "\n",
    "        image_level_cls_score = torch.sum(combined, dim=0) # y\n",
    "        # sum of combined may create value > 1.0\n",
    "        image_level_cls_score = torch.clamp(image_level_cls_score, min=0.0, max=1.0)\n",
    "        reg = alpha * wsddn.spatial_regulariser(regions[0], fc7, combined, gt_target[0])\n",
    "        loss = bce_loss(image_level_cls_score, gt_target[0])\n",
    "        out = loss + reg\n",
    "        \n",
    "        epoch_loss += out.item()\n",
    "        out.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred.append(image_level_cls_score.detach().cpu().numpy().tolist())\n",
    "        y_true.append(gt_target[0].detach().cpu().numpy().tolist())\n",
    "    cls_ap = []\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    for i in range(20):\n",
    "        cls_ap.append(average_precision_score(y_true[:,i], y_pred[:,i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
