{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from model import WSDDN_S, WSDDN_M\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import *\n",
    "from torch import optim\n",
    "from torchvision.ops import roi_pool, nms\n",
    "from pretrained import VGG_CNN_F, VGG_CNN_M_1024, VGG_VD_1024\n",
    "from VOCdatasets import VOCDectectionDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one2allbox_iou(target_box, others):\n",
    "    \"\"\"\n",
    "     calculate the iou of box A to list of boxes\n",
    "     target_box : Tensor()  1 * 4 \n",
    "     others : Tensor()      N * 4 \n",
    "     return  N * 1  ...iou\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # get the min of xmax and ymax which organize the Intersection\n",
    "    max_xy = torch.min(target_box[:, 2:], others[:, 2:]) \n",
    "    min_xy = torch.max(target_box[:, :2], others[:, :2])\n",
    "    # get the xdistance and y distance\n",
    "    # add 1 because distance = point2 - point1 + 1\n",
    "    inter_wh = torch.clamp((max_xy - min_xy + 1), min=0)\n",
    "    I = inter_wh[:, 0] * inter_wh[:, 1]\n",
    "    A = (target_box[:, 2] - target_box[:, 0] + 1) * (target_box[:, 3] - target_box[:, 1] + 1)\n",
    "    B = (others[:, 2] - others[:, 0] + 1) * (others[:, 3] - others[:, 1] + 1)\n",
    "    return I / (A + B - I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions[0]\n",
    "combine_scores = combined\n",
    "labels = gt_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[408.,   0., 479.,  33.],\n",
       "        [408.,   0., 479.,  41.],\n",
       "        [405.,   0., 479.,  48.],\n",
       "        ...,\n",
       "        [456., 298., 479., 319.],\n",
       "        [189., 298., 226., 319.],\n",
       "        [157., 298., 204., 319.]], device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([221.,  74.,  23.,  26., 220.,  98., 323., 101.,  37.,  77.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0011, 0.0011, 0.0011, 0.0011, 0.0010, 0.0010, 0.0009, 0.0009, 0.0009,\n",
       "        0.0009], device='cuda:0', grad_fn=<TopkBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou_th = 0.6\n",
    "# K = 10 #  top 10 scores\n",
    "# reg = 0\n",
    "# positives = 0\n",
    "# for c in range(20):\n",
    "#     # extract positive ones\n",
    "#     if labels[c].item() == 0:\n",
    "#         continue\n",
    "#     positives += 1\n",
    "#     topk_scores, topk_filter = combine_scores[:, c].topk(K, dim=0)\n",
    "#     topk_boxes = regions[topk_filter]\n",
    "#     topk_fc7 = fc7[topk_filter]\n",
    "    \n",
    "#     # get box with the best box | iou > 0.6\n",
    "#     iou_mask = one2allbox_iou(topk_boxes[0:1, :], topk_boxes).view(K)\n",
    "#     iou_mask = (iou_mask > iou_th).float()\n",
    "    \n",
    "#     fc7_diff = topk_fc7 - topk_fc7[0]\n",
    "#     score_diff = topk_scores.detach().view(K, 1)\n",
    "    \n",
    "#     diff = fc7_diff * score_diff\n",
    "    \n",
    "#     reg += 0.5 * (torch.pow(diff, 2).sum(1) * iou_mask).sum()\n",
    "    \n",
    "#     reg /= positives\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_regulariser(regions, fc7, combine_scores, labels):\n",
    "    iou_th = 0.6\n",
    "    K = 10 #  top 10 scores\n",
    "    reg = 0\n",
    "    positives = 0\n",
    "    for c in range(20):\n",
    "        # extract positive ones\n",
    "        if labels[c].item() == 0:\n",
    "            continue\n",
    "        positives += 1\n",
    "        topk_scores, topk_filter = combine_scores[:, c].topk(K, dim=0)\n",
    "        topk_boxes = regions[topk_filter]\n",
    "        topk_fc7 = fc7[topk_filter]\n",
    "        \n",
    "        # get box with the best box | iou > 0.6\n",
    "        iou_mask = one2allbox_iou(topk_boxes[0:1, :], topk_boxes).view(K)\n",
    "        iou_mask = (iou_mask > iou_th).float()\n",
    "        \n",
    "        fc7_diff = topk_fc7 - topk_fc7[0]\n",
    "        score_diff = topk_scores.detach().view(K, 1)\n",
    "        \n",
    "        diff = fc7_diff * score_diff\n",
    "        \n",
    "        reg += 0.5 * (torch.pow(diff, 2).sum(1) * iou_mask).sum()\n",
    "        \n",
    "        reg /= positives\n",
    "            \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSDDN_S(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WSDDN_S, self).__init__()\n",
    "        self.pretrain_net = VGG_CNN_F()\n",
    "        self.pretrain_net.load_mat()\n",
    "\n",
    "        self.roi_output_size = (6, 6)\n",
    "        \n",
    "        self.fc6 = nn.Linear(6*6*256, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8c = nn.Linear(4096, 20)\n",
    "        self.fc8d = nn.Linear(4096, 20)\n",
    "        \n",
    "    def forward(self, x, regions, scores=None):\n",
    "        #   x    : bs, c ,h, w\n",
    "        # regions: bs, R, 4\n",
    "        #  scores: bs, R\n",
    "        regions = [regions[0]] # roi_pool require [Tensor(K, 4)]\n",
    "        R = len(regions[0])\n",
    "        out = self.pretrain_net(x) # bs, 256， h/16, w/16\n",
    "        out = roi_pool(out, regions, self.roi_output_size, 1.0/16)  # R, 256, 6, 6\n",
    "        out = out.view(R, -1)\n",
    "\n",
    "        if scores is not None:\n",
    "            out = out * scores[0] * 10\n",
    "\n",
    "        out = F.relu(self.fc6(out))\n",
    "        out = F.relu(self.fc7(out))\n",
    "        \n",
    "        fc7 = out \n",
    "        # fc8x(out)   R, 20\n",
    "        cls_score = F.softmax(self.fc8c(out), dim = 1)\n",
    "        det_score = F.softmax(self.fc8d(out), dim = 0)\n",
    "        combined = cls_score * det_score\n",
    "\n",
    "        return combined, fc7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_07_trainval = VOCDectectionDataset(\"~/data/\", 2007, 'trainval')\n",
    "train_loader = data.DataLoader(voc_07_trainval, 1, shuffle=True)\n",
    "\n",
    "wsddn = WSDDN_S().to(DEVICE)\n",
    "\n",
    "wsddn.load_state_dict(torch.load(SAVE_PATH + \"ssw_2007_wsddn_s.pt\"))\n",
    "\n",
    "wsddn.train()\n",
    "optimizer = optim.SGD(wsddn.parameters(), lr=LR, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20], gamma=0.1)\n",
    "bce_loss = nn.BCELoss(reduction=\"mean\")\n",
    "N = len(train_loader)\n",
    "propose_way = 'eb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800717e346914ae2ab150294d1acf08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Total', max=20.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15f6c9ae62d4c6c803b00f7e916c1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 0', max=5011.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 classify AP is [nan, nan, nan, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, nan, nan, 1.0, nan, nan, nan, nan, nan]\n",
      "Epoch 0 classify mAP is nan\n",
      "Epoch 0 Loss is 5.61206337459262e-05\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 1e-1\n",
    "for epoch in tqdm(range(EPOCHS), \"Total\"):\n",
    "    epoch_loss = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    for img, gt_box, gt_target, regions, scores in tqdm(train_loader, f\"Epoch {epoch}\"):\n",
    "        optimizer.zero_grad()\n",
    "        # img   : Tensor(1, 3, h, w)\n",
    "        # gt_tar: Tensor(1, R_gt)\n",
    "        # region: Tensor(1, R, 4)\n",
    "        img = img.to(DEVICE)\n",
    "        regions = regions.to(DEVICE)\n",
    "        gt_target = gt_target.to(DEVICE)\n",
    "        if propose_way != \"edge_box\":\n",
    "            scores = None\n",
    "        else:\n",
    "            scores = scores.to(DEVICE)\n",
    "        combined, fc7 = wsddn(img, regions, scores=scores)\n",
    "        \n",
    "        image_level_cls_score = torch.sum(combined, dim=0) # y\n",
    "        \n",
    "        reg = alpha * spatial_regulariser(regions[0], fc7, combined, gt_target[0])\n",
    "        loss = bce_loss(image_level_cls_score, gt_target[0])\n",
    "        \n",
    "        out = loss + reg\n",
    "        \n",
    "        y_pred.append(image_level_cls_score.detach().cpu().numpy().tolist())\n",
    "        y_true.append(gt_target[0].detach().cpu().numpy().tolist())\n",
    "       \n",
    "        epoch_loss += out.item()\n",
    "        out.backward()\n",
    "        optimizer.step()\n",
    "        break\n",
    "    cls_ap = []\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    for i in range(20):\n",
    "        cls_ap.append(average_precision_score(y_true[:,i], y_pred[:,i]))\n",
    "    \n",
    "    print(f\"Epoch {epoch} classify AP is {str(cls_ap)}\")\n",
    "    print(f\"Epoch {epoch} classify mAP is {str(sum(cls_ap)/20)}\")\n",
    "    print(f\"Epoch {epoch} Loss is {epoch_loss/N}\")\n",
    "    print(\"-\" * 10)\n",
    "    scheduler.step()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1025, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.1787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(reg)\n",
    "print(gt_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1787, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y.append(image_level_cls_score.detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00014353, 0.00014353])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred_y)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2d24bf9d4805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "np.concatenate(np.array(pred_y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15438907993924983,\n",
       " 0.1399516771780243,\n",
       " 0.15653251484717573,\n",
       " 0.10210185269866995,\n",
       " 0.0923963152251606,\n",
       " 0.11109624669835773,\n",
       " 0.35321136563529093,\n",
       " 0.17532447611271065,\n",
       " 0.2134705714456663,\n",
       " 0.06527645240015797,\n",
       " 0.09321122799057938,\n",
       " 0.1800990635107902,\n",
       " 0.14303616964333313,\n",
       " 0.1510239025495608,\n",
       " 0.6474392721886746,\n",
       " 0.0968885852131021,\n",
       " 0.05644009620750633,\n",
       " 0.11363372686090151,\n",
       " 0.1525522964509208,\n",
       " 0.13825218855989238]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_list = [0 for _ in range(20)]\n",
    "for c in range(20):\n",
    "    ap_list[c] = cls_ap(pred_y[:, c], true_y[:, c])\n",
    "ap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_ap(pred, gt):\n",
    "    idx = np.argsort(-pred)\n",
    "    pred_sort = pred[idx]\n",
    "    gt_sort = gt[idx]\n",
    "    N = len(pred_sort)\n",
    "    ap_list = [0 for _ in range(N)]\n",
    "    for i in range(N): # every time to add one example to positive\n",
    "        all_positive = i + 1\n",
    "        true_positive = sum(gt_sort[:i+1])\n",
    "        if true_positive == 0.0:\n",
    "            ap_list[i] = 0\n",
    "        else:\n",
    "            ap_list[i] = true_positive/all_positive    \n",
    "    return sum(ap_list) / N\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1399516771780243"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_ap(pred_y[:, 1], true_y[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1868,  109, 4376, ..., 4461,  343,  164])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argsort(-x)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([true_y, pred_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = torch.Tensor(np.array([True, True, True, False]))\n",
    "\n",
    "yt = torch.Tensor(np.array([1, 1, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True, False, False,  True]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp == yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False,  True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
